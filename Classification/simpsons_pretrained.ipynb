{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install --upgrade torch\n\nfrom tqdm import tqdm, tqdm_notebook\nimport math\nimport random\nimport pickle\nimport pandas as pd\nimport numpy as np\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nimport time\nimport os\nfrom glob import glob\nimport torch\nimport torchvision\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom tqdm import tqdm, tqdm_notebook\n\nimport torch.nn as nn\nfrom PIL import Image\nfrom multiprocessing.pool import ThreadPool\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\n\n# Ignore warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nprint(\"PyTorch Version: \", torch.__version__)\nprint(\"Torchvision Version: \", torchvision.__version__)\n\ntrain_on_gpu = torch.cuda.is_available()\n\nif not train_on_gpu:\n    print('CUDA is not available.  Training on CPU ...')\nelse:\n    print('CUDA is available!  Training on GPU ...')","metadata":{"execution":{"iopub.status.busy":"2022-04-12T02:25:17.335040Z","iopub.execute_input":"2022-04-12T02:25:17.335377Z","iopub.status.idle":"2022-04-12T02:25:19.516579Z","shell.execute_reply.started":"2022-04-12T02:25:17.335288Z","shell.execute_reply":"2022-04-12T02:25:19.515619Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"PyTorch Version:  1.9.1\nTorchvision Version:  0.10.1\nCUDA is available!  Training on GPU ...\n","output_type":"stream"}]},{"cell_type":"code","source":"SEED = 42\n\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed(SEED)\ntorch.backends.cudnn.deterministic = True","metadata":{"execution":{"iopub.status.busy":"2022-04-12T02:25:22.971514Z","iopub.execute_input":"2022-04-12T02:25:22.972171Z","iopub.status.idle":"2022-04-12T02:25:22.982425Z","shell.execute_reply.started":"2022-04-12T02:25:22.972133Z","shell.execute_reply":"2022-04-12T02:25:22.981528Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"DATA_MODES = ['train', 'val', 'test']\nRESCALE_SIZE = 256\nDEVICE = torch.device(\"cuda\")","metadata":{"execution":{"iopub.status.busy":"2022-04-12T02:25:23.284770Z","iopub.execute_input":"2022-04-12T02:25:23.285331Z","iopub.status.idle":"2022-04-12T02:25:23.289631Z","shell.execute_reply.started":"2022-04-12T02:25:23.285291Z","shell.execute_reply":"2022-04-12T02:25:23.288847Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class SimpsonsDataset(Dataset):\n  def __init__(self, files, mode, augmentations = None):\n    super().__init__()\n    self.files = files\n    self.mode = mode\n    self.augmentations = augmentations\n\n    if self.mode not in DATA_MODES:\n      print(f'wrong mode: {self.mode}')\n      raise NameError\n\n    self.len_ = len(self.files)\n    self.label_encoder = LabelEncoder()\n\n    if self.mode != 'test':\n      self.labels = [path.parent.name for path in self.files]\n      self.label_encoder.fit(self.labels)\n\n      with open('label_encoder.pkl', 'wb') as le_dump:\n        pickle.dump(self.label_encoder, le_dump)\n\n  def __len__(self):\n    return self.len_\n\n  def load_sample(self, file):\n    image = Image.open(file)\n    image.load()\n    return image\n\n  def __getitem__(self, index):\n    transform = transforms.Compose([\n      transforms.Resize(256),\n      transforms.CenterCrop(224),  \n      transforms.ToTensor(),\n      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])                                \n    ])\n\n    x = self.load_sample(self.files[index])\n#     x = self._prepare_sample(x)\n#     x = np.array(x / 255, dtype='float32')\n\n    x = transform(x)\n  \n    if self.mode == 'test':\n      return x\n    else:\n    \n        \n      label = self.labels[index]\n      label_id = self.label_encoder.transform([label])\n      y = label_id.item()\n      return x, y\n\n#   def _prepare_sample(self, image):\n#     image = image.resize((RESCALE_SIZE, RESCALE_SIZE))\n#     return np.array(image)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T02:32:11.645603Z","iopub.execute_input":"2022-04-12T02:32:11.646057Z","iopub.status.idle":"2022-04-12T02:32:11.658082Z","shell.execute_reply.started":"2022-04-12T02:32:11.646024Z","shell.execute_reply":"2022-04-12T02:32:11.656923Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"class CustomImageDataset(Dataset):\n    def __init__(self, files, mode, augmentations = None):\n        super().__init__()\n        self.files = files\n        self.mode = mode\n        self.augmentations = augmentations\n        self.len_ = len(self.files)\n        self.label_encoder = LabelEncoder()\n        self.labels = [path.parent.name for path in self.files]\n        self.label_encoder.fit(self.labels)\n\n\n    def __len__(self):\n        return len(self.img_labels)\n\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n        image = read_image(img_path)\n        label = self.img_labels.iloc[idx, 1]\n        if self.transform:\n            image = self.transform(image)\n        if self.target_transform:\n            label = self.target_transform(label)\n        return image, label\n","metadata":{"execution":{"iopub.status.busy":"2022-04-12T02:32:34.220686Z","iopub.execute_input":"2022-04-12T02:32:34.220988Z","iopub.status.idle":"2022-04-12T02:32:34.230349Z","shell.execute_reply.started":"2022-04-12T02:32:34.220957Z","shell.execute_reply":"2022-04-12T02:32:34.229676Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"train_dir = Path('/kaggle/input/the-simpsons-characters-dataset/simpsons_dataset/')\ntest_dir = Path('/kaggle/input/the-simpsons-characters-dataset/kaggle_simpson_testset/')\nfiles_training = glob(os.path.join(train_dir,'simpsons_dataset', '*/*.jpg'))\nnum_images = len(files_training)\nprint('Number of images in Training file:', num_images)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T02:32:36.527387Z","iopub.execute_input":"2022-04-12T02:32:36.527933Z","iopub.status.idle":"2022-04-12T02:32:36.651369Z","shell.execute_reply.started":"2022-04-12T02:32:36.527894Z","shell.execute_reply":"2022-04-12T02:32:36.650544Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Number of images in Training file: 20933\n","output_type":"stream"}]},{"cell_type":"code","source":"min_images = 1000\nim_cnt = []\nclass_names = []\nprint('{:18s}'.format('class'), end='')\nprint('Count:')\nprint('-' * 24)\nfor folder in os.listdir(os.path.join(train_dir, 'simpsons_dataset')):\n    folder_num = len(os.listdir(os.path.join(train_dir,'simpsons_dataset',folder)))\n    im_cnt.append(folder_num)\n    class_names.append(folder)\n    print('{:20s}'.format(folder), end=' ')\n    print(folder_num)\n    if (folder_num < min_images):\n        min_images = folder_num\n        folder_name = folder\n        \nnum_classes = len(class_names)\nprint(\"\\nMinumum imgages per category:\", min_images, 'Category:', folder)    \nprint('Average number of Images per Category: {:.0f}'.format(np.array(im_cnt).mean()))\nprint('Total number of classes: {}'.format(num_classes))","metadata":{"execution":{"iopub.status.busy":"2022-04-12T02:32:37.375853Z","iopub.execute_input":"2022-04-12T02:32:37.376361Z","iopub.status.idle":"2022-04-12T02:32:37.423121Z","shell.execute_reply.started":"2022-04-12T02:32:37.376324Z","shell.execute_reply":"2022-04-12T02:32:37.422478Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"class             Count:\n------------------------\nrainier_wolfcastle   45\nmaggie_simpson       128\nkrusty_the_clown     1206\nwaylon_smithers      181\nprofessor_john_frink 65\nfat_tony             27\nralph_wiggum         89\notto_mann            32\nmartin_prince        71\nbarney_gumble        106\nned_flanders         1454\npatty_bouvier        72\nsideshow_mel         40\nmarge_simpson        1291\nabraham_grampa_simpson 913\nselma_bouvier        103\nmayor_quimby         246\ndisco_stu            8\nlionel_hutz          3\ntroy_mcclure         8\nagnes_skinner        42\ngroundskeeper_willie 121\nkent_brockman        498\ncharles_montgomery_burns 1193\ncarl_carlson         98\nchief_wiggum         986\napu_nahasapeemapetilon 623\nbart_simpson         1342\nedna_krabappel       457\ngil                  27\ncomic_book_guy       469\nprincipal_skinner    1194\ncletus_spuckler      47\nmilhouse_van_houten  1079\nsnake_jailbird       55\nnelson_muntz         358\nlisa_simpson         1354\nlenny_leonard        310\nmoe_szyslak          1452\nmiss_hoover          17\nhomer_simpson        2246\nsideshow_bob         877\n\nMinumum imgages per category: 3 Category: sideshow_bob\nAverage number of Images per Category: 498\nTotal number of classes: 42\n","output_type":"stream"}]},{"cell_type":"code","source":"train_val_files = sorted(list(train_dir.rglob('*.jpg')))\ntest_files = sorted(list(test_dir.rglob('*.jpg')))","metadata":{"execution":{"iopub.status.busy":"2022-04-12T02:32:40.069958Z","iopub.execute_input":"2022-04-12T02:32:40.070510Z","iopub.status.idle":"2022-04-12T02:32:43.202566Z","shell.execute_reply.started":"2022-04-12T02:32:40.070472Z","shell.execute_reply":"2022-04-12T02:32:43.201815Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"\n\nfrom sklearn.model_selection import train_test_split\n\ntrain_val_labels = [path.parent.name for path in train_val_files]\ntrain_files, val_files = train_test_split(train_val_files, test_size=0.3, \\\n                                          stratify=train_val_labels)\nval_labels = [path.parent.name for path in val_files]\nval_files, oos_files = train_test_split(val_files, test_size=0.4, stratify=val_labels)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-04-12T02:32:43.205265Z","iopub.execute_input":"2022-04-12T02:32:43.205774Z","iopub.status.idle":"2022-04-12T02:32:43.392874Z","shell.execute_reply.started":"2022-04-12T02:32:43.205735Z","shell.execute_reply":"2022-04-12T02:32:43.392119Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"\n\nval_dataset = SimpsonsDataset(val_files, mode='val')\ntrain_dataset = SimpsonsDataset(train_files, mode='train')\n\n","metadata":{"execution":{"iopub.status.busy":"2022-04-12T02:32:43.394043Z","iopub.execute_input":"2022-04-12T02:32:43.394292Z","iopub.status.idle":"2022-04-12T02:32:43.492772Z","shell.execute_reply.started":"2022-04-12T02:32:43.394259Z","shell.execute_reply":"2022-04-12T02:32:43.492068Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\ntest_dataset = SimpsonsDataset(test_files, mode=\"test\")\ntest_loader = DataLoader(test_dataset, shuffle=False, batch_size=64)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T02:32:43.494684Z","iopub.execute_input":"2022-04-12T02:32:43.494952Z","iopub.status.idle":"2022-04-12T02:32:43.500742Z","shell.execute_reply.started":"2022-04-12T02:32:43.494917Z","shell.execute_reply":"2022-04-12T02:32:43.499774Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# class Classifier(torch.nn.Module):\n#     def __init__(self, num_classes):\n#         super(Classifier, self).__init__()\n#         self.encoder = torchvision.models.resnet18(pretrained=True)\n#         self.linear_classifier = torch.nn.Linear(self.encoder.fc.out_features, num_classes)\n        \n#     def forward(self, sample):\n#         final_feature_map = self.encoder(sample)\n#         logits = self.linear_classifier(final_feature_map) # argmax(logits) = pred_class\n#         return logits","metadata":{"execution":{"iopub.status.busy":"2022-04-12T02:25:40.251177Z","iopub.execute_input":"2022-04-12T02:25:40.252130Z","iopub.status.idle":"2022-04-12T02:25:40.259804Z","shell.execute_reply.started":"2022-04-12T02:25:40.252089Z","shell.execute_reply":"2022-04-12T02:25:40.259047Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import torch.nn.functional as F\n\n\nclass Classifier(torch.nn.Module):\n\n    def __init__(self, num_classes: int):\n        super().__init__()\n        self.encoder = torchvision.models.mobilenet_v2(pretrained=False).features\n        self.classifier = torch.nn.Linear(\n            in_features=1280,  # For mobilenet_v2.\n            out_features=num_classes,\n        )\n\n    def forward(self, x):\n        feature_map = self.encoder(x)\n        pooled_features = F.adaptive_avg_pool2d(feature_map, (1, 1))\n        flattened_features = torch.flatten(pooled_features, 1)\n        logits = self.classifier(flattened_features)\n        return logits\n\n\nclassifier = Classifier(num_classes=10)\nprint(classifier(torch.ones((1, 3, 224, 224), dtype=torch.float32)))  # Test output of your neural network.","metadata":{"execution":{"iopub.status.busy":"2022-04-12T02:25:48.788715Z","iopub.execute_input":"2022-04-12T02:25:48.789737Z","iopub.status.idle":"2022-04-12T02:25:49.134754Z","shell.execute_reply.started":"2022-04-12T02:25:48.789684Z","shell.execute_reply":"2022-04-12T02:25:49.133935Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"tensor([[-0.3362, -0.1077, -0.0213,  0.4108, -0.0395, -0.3927, -0.1759,  0.2118,\n          0.0911, -0.3335]], grad_fn=<AddmmBackward>)\n","output_type":"stream"}]},{"cell_type":"code","source":"torchvision.models.resnet18().fc.out_features","metadata":{"execution":{"iopub.status.busy":"2022-04-12T02:25:53.545688Z","iopub.execute_input":"2022-04-12T02:25:53.545979Z","iopub.status.idle":"2022-04-12T02:25:53.748672Z","shell.execute_reply.started":"2022-04-12T02:25:53.545948Z","shell.execute_reply":"2022-04-12T02:25:53.747817Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"1000"},"metadata":{}}]},{"cell_type":"code","source":"torchvision.models.mobilenet_v2().features","metadata":{"execution":{"iopub.status.busy":"2022-04-05T10:56:46.514898Z","iopub.execute_input":"2022-04-05T10:56:46.515194Z","iopub.status.idle":"2022-04-05T10:56:46.602544Z","shell.execute_reply.started":"2022-04-05T10:56:46.515161Z","shell.execute_reply":"2022-04-05T10:56:46.60176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fit_epoch(model, train_loader, criterion, optimizer):\n    running_loss = 0.0\n    running_corrects = 0\n    processed_data = 0\n  \n    for inputs, labels in tqdm(train_loader):\n        inputs = inputs.to(DEVICE)\n        labels = labels.to(DEVICE)\n        optimizer.zero_grad()\n\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        preds = torch.argmax(outputs, 1)\n        running_loss += loss.item() * inputs.size(0)\n        running_corrects += torch.sum(preds == labels.data)\n        processed_data += inputs.size(0)\n              \n    train_loss = running_loss / processed_data\n    train_acc = running_corrects.cpu().numpy() / processed_data\n    return train_loss, train_acc\n  \ndef eval_epoch(model, val_loader, criterion):\n    model.eval()\n    running_loss = 0.0\n    running_corrects = 0\n    processed_size = 0\n\n    for inputs, labels in tqdm(val_loader):\n        inputs = inputs.to(DEVICE)\n        labels = labels.to(DEVICE)\n\n        with torch.set_grad_enabled(False):\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            preds = torch.argmax(outputs, 1)\n\n        running_loss += loss.item() * inputs.size(0)\n        running_corrects += torch.sum(preds == labels.data)\n        processed_size += inputs.size(0)\n    val_loss = running_loss / processed_size\n    val_acc = running_corrects.double() / processed_size\n    return val_loss, val_acc\n  \ndef train(train_files, val_files, model, epochs, batch_size):\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    print('Train data loader \\n')\n    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n    print('val data loader \\n')\n\n    history = []\n    log_template = \"\\nEpoch {ep:03d} train_loss: {t_loss:0.4f} \\\n    val_loss {v_loss:0.4f} train_acc {t_acc:0.4f} val_acc {v_acc:0.4f}\"\n\n    #with tqdm(desc=\"epoch\", total=epochs) as pbar_outer:\n        #Здесь можно добавить схему изменения learning rate\n        \n    opt = torch.optim.Adam(model.parameters(), lr = 1e-4)\n    criterion = nn.CrossEntropyLoss()\n\n    for epoch in range(epochs):\n        train_loss, train_acc = fit_epoch(model, train_loader, criterion, opt)\n#             print(\"loss\", train_loss)\n\n        val_loss, val_acc = eval_epoch(model, val_loader, criterion)\n        history.append((train_loss, train_acc, val_loss, val_acc))\n\n        # pbar_outer.update(1)\n        # tqdm.write(log_template.format(ep=epoch+1, t_loss=train_loss,\\\n        #                               v_loss=val_loss, t_acc=train_acc, v_acc=val_acc))\n        print(\"train loss: \" + str(train_loss) + \" train acc: \" + str(train_acc) + \" val loss: \" + str(val_loss) + \" val acc: \" + str(val_acc.item()))\n            \n    return history","metadata":{"execution":{"iopub.status.busy":"2022-04-12T03:05:05.367694Z","iopub.execute_input":"2022-04-12T03:05:05.367963Z","iopub.status.idle":"2022-04-12T03:05:05.384760Z","shell.execute_reply.started":"2022-04-12T03:05:05.367932Z","shell.execute_reply":"2022-04-12T03:05:05.383958Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"def predict(model, test_loader):\n    with torch.no_grad():\n        logits = []\n    \n        for inputs in test_loader:\n            inputs = inputs.to(DEVICE)\n            model.eval()\n            outputs = model(inputs).cpu()\n            logits.append(outputs)\n            \n    probs = nn.functional.softmax(torch.cat(logits), dim=-1).numpy()\n    return probs","metadata":{"execution":{"iopub.status.busy":"2022-04-12T03:05:08.520482Z","iopub.execute_input":"2022-04-12T03:05:08.520742Z","iopub.status.idle":"2022-04-12T03:05:08.527206Z","shell.execute_reply.started":"2022-04-12T03:05:08.520714Z","shell.execute_reply":"2022-04-12T03:05:08.526028Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"n_classes = len(np.unique(train_val_labels))\nmodel = Classifier(n_classes).to(DEVICE)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T03:05:09.166721Z","iopub.execute_input":"2022-04-12T03:05:09.167299Z","iopub.status.idle":"2022-04-12T03:05:09.280228Z","shell.execute_reply.started":"2022-04-12T03:05:09.167260Z","shell.execute_reply":"2022-04-12T03:05:09.279469Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"np.unique(train_val_labels)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T03:05:09.738349Z","iopub.execute_input":"2022-04-12T03:05:09.741153Z","iopub.status.idle":"2022-04-12T03:05:09.786582Z","shell.execute_reply.started":"2022-04-12T03:05:09.741104Z","shell.execute_reply":"2022-04-12T03:05:09.785914Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"array(['abraham_grampa_simpson', 'agnes_skinner',\n       'apu_nahasapeemapetilon', 'barney_gumble', 'bart_simpson',\n       'carl_carlson', 'charles_montgomery_burns', 'chief_wiggum',\n       'cletus_spuckler', 'comic_book_guy', 'disco_stu', 'edna_krabappel',\n       'fat_tony', 'gil', 'groundskeeper_willie', 'homer_simpson',\n       'kent_brockman', 'krusty_the_clown', 'lenny_leonard',\n       'lionel_hutz', 'lisa_simpson', 'maggie_simpson', 'marge_simpson',\n       'martin_prince', 'mayor_quimby', 'milhouse_van_houten',\n       'miss_hoover', 'moe_szyslak', 'ned_flanders', 'nelson_muntz',\n       'otto_mann', 'patty_bouvier', 'principal_skinner',\n       'professor_john_frink', 'rainier_wolfcastle', 'ralph_wiggum',\n       'selma_bouvier', 'sideshow_bob', 'sideshow_mel', 'snake_jailbird',\n       'troy_mcclure', 'waylon_smithers'], dtype='<U24')"},"metadata":{}}]},{"cell_type":"code","source":"\nhistory = train(train_dataset, val_dataset, model=model, epochs=15, batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T15:17:32.512738Z","iopub.execute_input":"2022-04-06T15:17:32.513029Z","iopub.status.idle":"2022-04-06T16:39:09.828244Z","shell.execute_reply.started":"2022-04-06T15:17:32.512999Z","shell.execute_reply":"2022-04-06T16:39:09.825699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(), \"saved_model.pth\")","metadata":{"execution":{"iopub.status.busy":"2022-04-06T16:39:09.830122Z","iopub.execute_input":"2022-04-06T16:39:09.830402Z","iopub.status.idle":"2022-04-06T16:39:09.877982Z","shell.execute_reply.started":"2022-04-06T16:39:09.830363Z","shell.execute_reply":"2022-04-06T16:39:09.877333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if(\"saved_model.pth\" in os.listdir(\".\")):\n    model.load_state_dict(torch.load(\"saved_model.pth\"))","metadata":{"execution":{"iopub.status.busy":"2022-04-06T16:39:53.786435Z","iopub.execute_input":"2022-04-06T16:39:53.786953Z","iopub.status.idle":"2022-04-06T16:39:53.846928Z","shell.execute_reply.started":"2022-04-06T16:39:53.786914Z","shell.execute_reply":"2022-04-06T16:39:53.846302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = train(train_dataset, val_dataset, model=model, epochs=5, batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T16:40:46.482573Z","iopub.execute_input":"2022-04-06T16:40:46.482835Z","iopub.status.idle":"2022-04-06T17:06:30.743383Z","shell.execute_reply.started":"2022-04-06T16:40:46.482805Z","shell.execute_reply":"2022-04-06T17:06:30.742674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Classifier2(torch.nn.Module):\n\n    def __init__(self, num_classes: int):\n        super().__init__()\n        self.encoder = torchvision.models.mobilenet_v2(pretrained=True).features\n        self.classifier = torch.nn.Linear(\n            in_features=1280,  # For mobilenet_v2.\n            out_features=num_classes,\n        )\n\n    def forward(self, x):\n        feature_map = self.encoder(x)\n        pooled_features = F.adaptive_avg_pool2d(feature_map, (1, 1))\n        flattened_features = torch.flatten(pooled_features, 1)\n        logits = self.classifier(flattened_features)\n        return logits","metadata":{"execution":{"iopub.status.busy":"2022-04-12T03:05:14.896085Z","iopub.execute_input":"2022-04-12T03:05:14.896677Z","iopub.status.idle":"2022-04-12T03:05:14.903072Z","shell.execute_reply.started":"2022-04-12T03:05:14.896635Z","shell.execute_reply":"2022-04-12T03:05:14.902180Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"model2 = Classifier2(n_classes).to(DEVICE)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T03:05:15.467653Z","iopub.execute_input":"2022-04-12T03:05:15.468222Z","iopub.status.idle":"2022-04-12T03:05:15.587901Z","shell.execute_reply.started":"2022-04-12T03:05:15.468184Z","shell.execute_reply":"2022-04-12T03:05:15.587167Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"history2 = train(train_dataset, val_dataset, model=model2, epochs=5, batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T03:05:16.214643Z","iopub.execute_input":"2022-04-12T03:05:16.214910Z","iopub.status.idle":"2022-04-12T03:30:54.434739Z","shell.execute_reply.started":"2022-04-12T03:05:16.214875Z","shell.execute_reply":"2022-04-12T03:30:54.434036Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"Train data loader \n\nval data loader \n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 916/916 [04:16<00:00,  3.57it/s]\n100%|██████████| 236/236 [00:54<00:00,  4.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"train loss: 0.5483097536795084 train acc: 0.8801610591687709 val loss: 0.12986927495719647 val acc: 0.9704087048832272\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 916/916 [04:15<00:00,  3.58it/s]\n100%|██████████| 236/236 [00:50<00:00,  4.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"train loss: 0.15973138793282698 train acc: 0.95929161263905 val loss: 0.1330784114914098 val acc: 0.9633757961783439\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 916/916 [04:17<00:00,  3.56it/s]\n100%|██████████| 236/236 [00:50<00:00,  4.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"train loss: 0.06633412364960817 train acc: 0.9818467208080257 val loss: 0.07816050464552857 val acc: 0.980228237791932\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 916/916 [04:16<00:00,  3.57it/s]\n100%|██████████| 236/236 [00:51<00:00,  4.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"train loss: 0.039036425001917556 train acc: 0.9887053845628881 val loss: 0.07861121501669786 val acc: 0.9792993630573248\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 916/916 [04:14<00:00,  3.60it/s]\n100%|██████████| 236/236 [00:50<00:00,  4.65it/s]","output_type":"stream"},{"name":"stdout","text":"train loss: 0.03148371529326985 train acc: 0.9910598512250052 val loss: 0.1716242297003817 val acc: 0.9554140127388535\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(model.state_dict(), \"saved_model_pretrained.pth\")","metadata":{"execution":{"iopub.status.busy":"2022-04-12T03:33:14.377844Z","iopub.execute_input":"2022-04-12T03:33:14.378376Z","iopub.status.idle":"2022-04-12T03:33:14.427073Z","shell.execute_reply.started":"2022-04-12T03:33:14.378339Z","shell.execute_reply":"2022-04-12T03:33:14.426380Z"},"trusted":true},"execution_count":45,"outputs":[]}]}